{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === 線形モデルとニューラルネットワーク ===\n",
    "\n",
    "# ニューラルネットワークを適用する例題として、アヤメの種判別問題に取り組みます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 多層パーセプトロンを適用\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# サンプルデータの読み込み\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# テストデータと訓練データに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの標準化を行う\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === データの読み込みと整形 ===\n",
    "\n",
    "# scikit-learnに組み込まれているアヤメの種類別の形質データを使います。\n",
    "# load_iris関数を使ってデータを読み込みます。\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの中身はガクと花弁の長さと幅のデータです。\n",
    "# 説明変数（入力ベクトル）の名称を取得します。\n",
    "\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 次は応答変数を調べます。３種類のアヤメがあることがわかります。\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "説明変数の行列・列数： (100, 2)\n",
      "応答変数の行列・列数： (100,)\n"
     ]
    }
   ],
   "source": [
    "# 説明変数はiris.data, 応答変数はiris.targetに格納されています。\n",
    "\n",
    "# 今回は全てのデータではなく、説明変数は２種類だけ、アヤメの種類も２種類に絞ります。\n",
    "# 50行ごとにアヤメの種類は変わるので[50 : 150]と指定してデータを取得します。\n",
    "\n",
    "# 説明変数をsepal(ガク)だけにする\n",
    "X = iris.data[50: 150, 0: 2]\n",
    "\n",
    "# アヤメを２種類だけにする\n",
    "y = iris.target[50 :150]\n",
    "\n",
    "print(\"説明変数の行列・列数：\", X.shape)\n",
    "print(\"応答変数の行列・列数：\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "説明変数の行列・列数： (75, 2)\n",
      "応答変数の行列・列数： (75,)\n"
     ]
    }
   ],
   "source": [
    "# 予測精度を評価するために、訓練データとテストデータに分割します。\n",
    "# 再現性を保つためにrandom_stateで乱数の種を指定します。\n",
    "\n",
    "# データを訓練データとテストデータに分ける ( train : test = 75% : 25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, random_state = 2)\n",
    "\n",
    "print(\"説明変数の行列・列数：\", X_train.shape)\n",
    "print(\"応答変数の行列・列数：\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 2, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === ロジスティック回帰 ===\n",
    "\n",
    "# ニューラルネットワークを実装する前に、ロジスティック回帰を用いた分類を試みます。\n",
    "\n",
    "# まずは応答変数がどのようなデータなのかを確認します。\n",
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   species  sepal_len  sepal_wid\n",
      "0        0        5.7        2.8\n",
      "1        0        6.6        3.0\n",
      "2        1        6.1        3.0\n"
     ]
    }
   ],
   "source": [
    "# 1番と2番で別の種であることを表しています。これをロジスティック回帰にょって、自動で種類判別ができるようにしようというのが今回やることです。\n",
    "# statsmodelsを使ってロジスティック回帰を実行することにします。そのためにはまずはデータフレームにまとめます。\n",
    "# また、応答変数は０か１になるように１を引いておくことにします。\n",
    "\n",
    "# データの整形\n",
    "# 説目変数のデータフレーム\n",
    "X_train_df = pd.DataFrame(X_train, columns = [\"sepal_len\", \"sepal_wid\"])\n",
    "\n",
    "# 応答変数のデータフレーム\n",
    "y_train_df = pd.DataFrame({\"species\": y_train - 1})\n",
    "\n",
    "# デーヤフレームを結合\n",
    "iris_train_df = pd.concat([y_train_df, X_train_df], axis = 1)\n",
    "\n",
    "# 結果を出力\n",
    "print(iris_train_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full 76.813\n",
      "len 76.234\n",
      "wid 92.768\n",
      "null 105.318\n"
     ]
    }
   ],
   "source": [
    "# モデル化\n",
    "# 全ての変数を入れたモデル\n",
    "logi_mod_full = smf.glm(\"species ~ sepal_len + sepal_wid\", data = iris_train_df, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# 長さのみ\n",
    "logi_mod_len = smf.glm(\"species ~ sepal_len\", data = iris_train_df, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# 幅のみ\n",
    "logi_mod_wid = smf.glm(\"species ~ sepal_wid\", data = iris_train_df, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# Nullモデル\n",
    "logi_mod_null = smf.glm(\"species ~ 1\", data = iris_train_df, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# AICの比較\n",
    "print(\"full\", logi_mod_full.aic.round(3))\n",
    "print(\"len\", logi_mod_len.aic.round(3))\n",
    "print(\"wid\", logi_mod_wid.aic.round(3))\n",
    "print(\"null\", logi_mod_null.aic.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -16.4152</td> <td>    4.000</td> <td>   -4.104</td> <td> 0.000</td> <td>  -24.256</td> <td>   -8.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_len</th> <td>    2.6478</td> <td>    0.639</td> <td>    4.142</td> <td> 0.000</td> <td>    1.395</td> <td>    3.901</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# わずかですがガクの長さだけを使ったモデルの方がAICが低くなったためlogi_mod_lenを採用します。\n",
    "\n",
    "# 推定された係数を確認します。ガクの長さは正の係数を持っていました。\n",
    "# そのため。ガクの長さが大きくなると種２になりやすいということがわかります。\n",
    "logi_mod_len.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの的中率　： 0.746666666667\n",
      "テストデータの的中率　： 0.68\n"
     ]
    }
   ],
   "source": [
    "# 最後に訓練データへの当てはめ精度と、テストデータへの予測精度を確認します。\n",
    "\n",
    "# データの整形\n",
    "X_test_df = pd. DataFrame(X_test, columns = [\"sepal_len\", \"sepal_wid\"])\n",
    "\n",
    "# 当てはめと予測\n",
    "logi_fit = logi_mod_len.fittedvalues.round(0)\n",
    "logi_pred = logi_mod_len.predict(X_test_df).round(0)\n",
    "\n",
    "# 正答率\n",
    "true_train = sp.sum(logi_fit == (y_train - 1))\n",
    "true_test = sp.sum(logi_pred == (y_test - 1))\n",
    "\n",
    "# 的中率\n",
    "result_train = true_train / len(y_train)\n",
    "result_test = true_test / len(y_test)\n",
    "\n",
    "# 結果の出力\n",
    "print(\"訓練データの的中率　：\", result_train)\n",
    "print(\"テストデータの的中率　：\", result_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # 訓練データもテストデータもおよそ７割は的中しているようです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 標準化 ===\n",
    "\n",
    "# 続いてニューラルネットワークに移ります。\n",
    "\n",
    "# 標準化のための準備\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# 標準化する\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データの説明変数の標準偏差が１になっていることを確認します\n",
    "sp.std(X_train_scaled, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74 ,  0.679])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータの場合は標準偏差が１になるとは限りません。これは正しい結果です。\n",
    "# 訓練データとテストデータでは全く同じ変換を適用するのが重要です。私たちはまだテストデータを手にしていないことが前提だからです。\n",
    "sp.std(X_test_scaled, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの的中率： 0.893333333333\n",
      "テストデータの的中率： 0.68\n"
     ]
    }
   ],
   "source": [
    "# === ニューラルネットワーク ===\n",
    "\n",
    "# ニューラルネットワークを適用し、その当てはめ精度とテストデータへの予測精度を出力するコードは以下の通りです。\n",
    "nnet = MLPClassifier (hidden_layer_sizes = (100,100), \n",
    "                                     alpha = 0.07,\n",
    "                                     max_iter = 10000,\n",
    "                                     random_state = 0)\n",
    "nnet.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 正答率\n",
    "print(\"訓練データの的中率：\", nnet.score(X_train_scaled, y_train))\n",
    "print(\"テストデータの的中率：\", nnet.score(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
